{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s95-ph5YtqBZ"
      },
      "source": [
        "## **Child Mind Institute - Detect Sleep States**"
      ],
      "id": "s95-ph5YtqBZ"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "udkFfnKOr_He"
      },
      "source": [
        "## ***Project participants:*** Alexandra Serechenko and Maria Zueva"
      ],
      "id": "udkFfnKOr_He"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fm3xJanOsDCe"
      },
      "source": [
        "### Link to the competition: https://www.kaggle.com/competitions/child-mind-institute-detect-sleep-states/data?select=test_series.parquet"
      ],
      "id": "Fm3xJanOsDCe"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_9qy72CCuERs"
      },
      "source": [
        "### Sleeping plays a crucial role in maintaining health and well-being. Sleep is a complex physiological process that contributes to cognition, emotional regulation, immune system, and metabolic balance work. Good-quality sleep is essential for maintaining memory, learning, and problem-solving. It supports physical recovery, helps body to repair tissues and muscles.\n"
      ],
      "id": "_9qy72CCuERs"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x-N4YVgRsS1C"
      },
      "source": [
        "### **The main goal**: to detect sleep onset and wake."
      ],
      "id": "x-N4YVgRsS1C"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PArNEU92vC8u"
      },
      "source": [
        "### The results when obtained, can be used in the future in order to improve researchers' ability to analyze accelerometer data for speed monitoring and enable them to conduct large-scale studies of sleep. Also the competition itself has a mission to improve awareness and guidance surrounding the importance of sleep."
      ],
      "id": "PArNEU92vC8u"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BzgZwa3vuQYb"
      },
      "source": [
        "### **Description of sleep data:**\n",
        "\n",
        "- approximately 500 multi-day recordings of wrist-worn accelerometer data annotated with two event types: onset, the beginning of sleep, and wakeup, the end of sleep.  In this work, we will use 3 files that are publicly available to the participants of the competition:\n",
        "1. train_series.parquet - Series to be used as training data. Each series - continuous recording of accelerometer data for a single subject spanning many days.\n",
        "2. test_series.parquet - Series to be used as the test data, containing the same fields as above.\n",
        "\n",
        "3. train_events.csv - Sleep logs for series in the training set recording onset and wake events."
      ],
      "id": "BzgZwa3vuQYb"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vUU-yzR9PjQq",
        "outputId": "c5259fa4-217a-4d40-bbcd-0a7f5d768e95"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "id": "vUU-yzR9PjQq"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "NNu7-tbxRfg3",
        "outputId": "e332d5e3-05e7-4037-e0f5-eb07a153bc78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found existing installation: polars 0.17.3\n",
            "Uninstalling polars-0.17.3:\n",
            "  Would remove:\n",
            "    /usr/local/lib/python3.10/dist-packages/polars-0.17.3.dist-info/*\n",
            "    /usr/local/lib/python3.10/dist-packages/polars/*\n",
            "Proceed (Y/n)? y\n",
            "  Successfully uninstalled polars-0.17.3\n",
            "Collecting polars\n",
            "  Downloading polars-0.19.19-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (28.5 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m28.5/28.5 MB\u001b[0m \u001b[31m28.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: polars\n",
            "Successfully installed polars-0.19.19\n"
          ]
        }
      ],
      "source": [
        "!pip uninstall polars\n",
        "!pip install polars"
      ],
      "id": "NNu7-tbxRfg3"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "227cb13f"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import plotly.express as px\n",
        "from plotly.subplots import make_subplots\n",
        "import plotly.graph_objects as go\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import polars as pl\n",
        "\n",
        "from event_detection_ap import score\n",
        "\n",
        "import datetime\n",
        "from tqdm import tqdm"
      ],
      "id": "227cb13f"
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Variables for the score function\n",
        "\n",
        "column_names = {\n",
        "    'series_id_column_name': 'series_id',\n",
        "    'time_column_name': 'step',\n",
        "    'event_column_name': 'event',\n",
        "    'score_column_name': 'score',\n",
        "}\n",
        "\n",
        "tolerances = {\n",
        "    'onset': [12, 36, 60, 90, 120, 150, 180, 240, 300, 360],\n",
        "    'wakeup': [12, 36, 60, 90, 120, 150, 180, 240, 300, 360]\n",
        "}"
      ],
      "metadata": {
        "id": "COxU1LjjaSrk"
      },
      "id": "COxU1LjjaSrk",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rOpmDnlvPtWR"
      },
      "outputs": [],
      "source": [
        "review_data = pd.read_csv('/content/drive/My Drive/train_events.csv')"
      ],
      "id": "rOpmDnlvPtWR"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "68a4536c"
      },
      "source": [
        "## Data transformations"
      ],
      "id": "68a4536c"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "b47def8d"
      },
      "outputs": [],
      "source": [
        "# import data, transform the columns\n",
        "\n",
        "dt_transforms = [\n",
        "    pl.col('timestamp').str.to_datetime(),\n",
        "    (pl.col('timestamp').str.to_datetime().dt.year()-2000).cast(pl.UInt8).alias('year'),\n",
        "    pl.col('timestamp').str.to_datetime().dt.month().cast(pl.UInt8).alias('month'),\n",
        "    pl.col('timestamp').str.to_datetime().dt.day().cast(pl.UInt8).alias('day'),\n",
        "    pl.col('timestamp').str.to_datetime().dt.hour().cast(pl.UInt8).alias('hour')\n",
        "]\n",
        "\n",
        "data_transforms = [\n",
        "    # Convert anglez to 16 bit integer\n",
        "    pl.col('anglez').cast(pl.Int16),\n",
        "    # Convert enmo to 16 bit uint\n",
        "    (pl.col('enmo')*1000).cast(pl.UInt16),\n",
        "]"
      ],
      "id": "b47def8d"
    },
    {
      "cell_type": "code",
      "source": [
        "train_series = pl.scan_parquet('/content/drive/My Drive/train_series.parquet').with_columns(\n",
        "    dt_transforms + data_transforms\n",
        "    )\n",
        "\n",
        "train_events = pl.read_csv('/content/drive/My Drive/train_events.csv').with_columns(\n",
        "    dt_transforms\n",
        "    ).drop_nulls()\n",
        "\n",
        "test_series = pl.scan_parquet('/content/drive/My Drive/test_series.parquet').with_columns(\n",
        "    dt_transforms + data_transforms\n",
        "    )\n"
      ],
      "metadata": {
        "id": "4FKEhmz_aY__"
      },
      "id": "4FKEhmz_aY__",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Remove null events and nights with mismatched counts from series_events\n",
        "\n",
        "mismatches = train_events.drop_nulls().group_by(['series_id', 'night']).agg([\n",
        "    ((pl.col('event') == 'onset').sum() == (pl.col('event') == 'wakeup').sum()).alias('balanced')\n",
        "    ]).sort(by=['series_id', 'night']).filter(~pl.col('balanced'))\n",
        "\n",
        "for mm in mismatches.to_numpy():\n",
        "    train_events = train_events.filter(~((pl.col('series_id') == mm[0]) & (pl.col('night') == mm[1])))\n",
        "\n",
        "# Series ids --> list\n",
        "series_ids = train_events['series_id'].unique(maintain_order=True).to_list()\n",
        "\n",
        "# Keep only these series ids in train_series\n",
        "train_series = train_series.filter(pl.col('series_id').is_in(series_ids))"
      ],
      "metadata": {
        "id": "-MQQ1lUQab4Q"
      },
      "id": "-MQQ1lUQab4Q",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "57ba326f"
      },
      "source": [
        "**Useful parameters for the model**\n",
        "\n",
        "It is possible to show that the parameter anglez (\"a metric derived from individual accelerometer components that is commonly used in sleep detection, and refers to the angle of the arm relative to the vertical axis of the body\", https://www.kaggle.com/competitions/child-mind-institute-detect-sleep-states/data) varies constantly during waking hours, while during sleep hours it almost doesn't change. So it is reasonable to take the total variation of the values of this parameter as a distinguishing factor between awakeness and sleep (the sum of the absolute difference between points). For the waking person it is unlimiting while for the sleeping person it is a limited value."
      ],
      "id": "57ba326f"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_eEbYj2neZiu"
      },
      "source": [
        "**Notes for the code cells below:**\n",
        "\n",
        "- *Initialization of Features and Feature Columns:*\n",
        "\n",
        "features: Initialize with the 'hour' column from the original DataFrame. The base for further feature engineering.\n",
        "feature_cols: Initialized with the column names, starting with 'hour'.\n",
        "\n",
        "- *Nested Loops for Feature Engineering:*\n",
        "\n",
        "For each combination of duration and variable, generate rolling features (mean, max, and standard deviation) based on the absolute values of the variable.\n",
        "\n",
        "Generate first-order variations  of the variables, calculate rolling mean, max, and standard deviation for the variations, scale the results by a factor of 10.\n",
        "\n",
        "- *Update features and feature_cols:*\n",
        "\n",
        "After each iteration of the inner loops, append the generated features and corresponding column names to the features and feature_cols lists.\n",
        "\n",
        "- *Update train_series and test_series:*\n",
        "\n",
        "For train_series and test_series add the calculated features to the DataFrame using the with_columns method.\n",
        "\n",
        "Select DataFrame to include only the specified identifier columns (id_cols) and the newly created feature columns (feature_cols).\n",
        "\n",
        "Rolling window feature engineering on the 'enmo' and 'anglez' variables for different durations (5 minutes, 30 minutes, 2 hours, and 8 hours).\n",
        "\n",
        "- Calculate rolling mean, max, and standard deviation for the absolute values and the first-order variations of the variables.\n",
        "\n",
        "Add the resulting features to the original time series (train_series and test_series)."
      ],
      "id": "_eEbYj2neZiu"
    },
    {
      "cell_type": "code",
      "source": [
        "features, feature_cols = [pl.col('hour')], ['hour']"
      ],
      "metadata": {
        "id": "fuJIAQkdajvV"
      },
      "id": "fuJIAQkdajvV",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cecd351"
      },
      "outputs": [],
      "source": [
        "for mins in [5, 30, 60*2, 60*8] :\n",
        "\n",
        "    for var in ['enmo', 'anglez'] :\n",
        "\n",
        "        features += [\n",
        "            pl.col(var).rolling_mean(12 * mins, center=True, min_periods=1).abs().cast(pl.UInt16).alias(f'{var}_{mins}m_mean'),\n",
        "            pl.col(var).rolling_max(12 * mins, center=True, min_periods=1).abs().cast(pl.UInt16).alias(f'{var}_{mins}m_max'),\n",
        "            pl.col(var).rolling_std(12 * mins, center=True, min_periods=1).abs().cast(pl.UInt16).alias(f'{var}_{mins}m_std')\n",
        "        ]\n",
        "\n",
        "        feature_cols += [\n",
        "            f'{var}_{mins}m_mean', f'{var}_{mins}m_max', f'{var}_{mins}m_std'\n",
        "        ]\n",
        "\n",
        "        # Getting first variations\n",
        "        features += [\n",
        "            (pl.col(var).diff().abs().rolling_mean(12 * mins, center=True, min_periods=1)*10).abs().cast(pl.UInt32).alias(f'{var}_1v_{mins}m_mean'),\n",
        "            (pl.col(var).diff().abs().rolling_max(12 * mins, center=True, min_periods=1)*10).abs().cast(pl.UInt32).alias(f'{var}_1v_{mins}m_max'),\n",
        "            (pl.col(var).diff().abs().rolling_std(12 * mins, center=True, min_periods=1)*10).abs().cast(pl.UInt32).alias(f'{var}_1v_{mins}m_std')\n",
        "        ]\n",
        "\n",
        "        feature_cols += [\n",
        "            f'{var}_1v_{mins}m_mean', f'{var}_1v_{mins}m_max', f'{var}_1v_{mins}m_std'\n",
        "        ]\n",
        "\n",
        "id_cols = ['series_id', 'step', 'timestamp']\n",
        "\n",
        "train_series = train_series.with_columns(\n",
        "    features\n",
        ").select(id_cols + feature_cols)\n",
        "\n",
        "test_series = test_series.with_columns(\n",
        "    features\n",
        ").select(id_cols + feature_cols)"
      ],
      "id": "5cecd351"
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Iterate over series IDs, normalize features\n",
        "\n",
        "- Construct the feature matrix and labels for the training dataset\n",
        "\n",
        "- The labels are determined based on the occurrence of steps within specified intervals corresponding to events in the 'train_events' DataFrame"
      ],
      "metadata": {
        "id": "K719Toz7YsAz"
      },
      "id": "K719Toz7YsAz"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e700c73d"
      },
      "outputs": [],
      "source": [
        "def make_train_dataset(train_data, train_events, drop_nulls=False) :\n",
        "\n",
        "    series_ids = train_data['series_id'].unique(maintain_order=True).to_list()\n",
        "    X, y = pl.DataFrame(), pl.DataFrame()\n",
        "    for idx in tqdm(series_ids) :\n",
        "\n",
        "        # Normalizing sample features\n",
        "        sample = train_data.filter(pl.col('series_id')==idx).with_columns(\n",
        "            [(pl.col(col) / pl.col(col).std()).cast(pl.Float32) for col in feature_cols if col != 'hour']\n",
        "        )\n",
        "\n",
        "        events = train_events.filter(pl.col('series_id')==idx)\n",
        "\n",
        "        if drop_nulls :\n",
        "            # Removing datapoints on dates where no data was recorded\n",
        "            sample = sample.filter(\n",
        "                pl.col('timestamp').dt.date().is_in(events['timestamp'].dt.date())\n",
        "            )\n",
        "\n",
        "        X = X.vstack(sample[id_cols + feature_cols])\n",
        "\n",
        "        onsets = events.filter((pl.col('event') == 'onset') & (pl.col('step') != None))['step'].to_list()\n",
        "        wakeups = events.filter((pl.col('event') == 'wakeup') & (pl.col('step') != None))['step'].to_list()\n",
        "\n",
        "        # NOTE: This will break if there are event series without any recorded onsets or wakeups\n",
        "        y = y.vstack(sample.with_columns(\n",
        "            sum([(onset <= pl.col('step')) & (pl.col('step') <= wakeup) for onset, wakeup in zip(onsets, wakeups)]).cast(pl.Boolean).alias('asleep')\n",
        "            ).select('asleep')\n",
        "            )\n",
        "\n",
        "    y = y.to_numpy().ravel()\n",
        "\n",
        "    return X, y"
      ],
      "id": "e700c73d"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WWxiC176e0Rd"
      },
      "source": [
        "- Process a time series using a classifier to predict sleep events (onset and wakeup)\n",
        "\n",
        "- Calculate scores for each predicted sleep period based on the mean probability over the period\n",
        "- Store the results in a formatted DataFrame\n",
        "- Reset the row index to create a 'row_id' column. The final DataFrame is returned as the output."
      ],
      "id": "WWxiC176e0Rd"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5cdd419d"
      },
      "outputs": [],
      "source": [
        "def get_events(series, classifier) :\n",
        "    '''\n",
        "    Takes a time series and a classifier and returns a formatted submission dataframe.\n",
        "    '''\n",
        "\n",
        "    series_ids = series['series_id'].unique(maintain_order=True).to_list()\n",
        "    events = pl.DataFrame(schema={'series_id':str, 'step':int, 'event':str, 'score':float})\n",
        "\n",
        "    for idx in tqdm(series_ids) :\n",
        "\n",
        "        # Collect sample and normalize features\n",
        "        scale_cols = [col for col in feature_cols if (col != 'hour') & (series[col].std() !=0)]\n",
        "        X = series.filter(pl.col('series_id') == idx).select(id_cols + feature_cols).with_columns(\n",
        "            [(pl.col(col) / series[col].std()).cast(pl.Float32) for col in scale_cols]\n",
        "        )\n",
        "\n",
        "        # Apply classifier to get predictions and scores\n",
        "        preds, probs = classifier.predict(X[feature_cols]), classifier.predict_proba(X[feature_cols])[:, 1]\n",
        "\n",
        "\n",
        "        X = X.with_columns(\n",
        "            pl.lit(preds).cast(pl.Int8).alias('prediction'),\n",
        "            pl.lit(probs).alias('probability')\n",
        "                        )\n",
        "\n",
        "        # Get predicted onset and wakeup time steps\n",
        "        pred_onsets = X.filter(X['prediction'].diff() > 0)['step'].to_list()\n",
        "        pred_wakeups = X.filter(X['prediction'].diff() < 0)['step'].to_list()\n",
        "\n",
        "        if len(pred_onsets) > 0 :\n",
        "\n",
        "            # Ensure all predicted sleep periods begin and end\n",
        "            if min(pred_wakeups) < min(pred_onsets) :\n",
        "                pred_wakeups = pred_wakeups[1:]\n",
        "\n",
        "            if max(pred_onsets) > max(pred_wakeups) :\n",
        "                pred_onsets = pred_onsets[:-1]\n",
        "\n",
        "            # Keep sleep periods longer than 30 minutes\n",
        "            sleep_periods = [(onset, wakeup) for onset, wakeup in zip(pred_onsets, pred_wakeups) if wakeup - onset >= 12 * 30]\n",
        "\n",
        "            for onset, wakeup in sleep_periods :\n",
        "                # Score using mean probability over period\n",
        "                score = X.filter((pl.col('step') >= onset) & (pl.col('step') <= wakeup))['probability'].mean()\n",
        "\n",
        "                # Add sleep event to dataframe\n",
        "                events = events.vstack(pl.DataFrame().with_columns(\n",
        "                    pl.Series([idx, idx]).alias('series_id'),\n",
        "                    pl.Series([onset, wakeup]).alias('step'),\n",
        "                    pl.Series(['onset', 'wakeup']).alias('event'),\n",
        "                    pl.Series([score, score]).alias('score')\n",
        "                ))\n",
        "\n",
        "    # Add row id column\n",
        "    events = events.to_pandas().reset_index().rename(columns={'index':'row_id'})\n",
        "\n",
        "    return events"
      ],
      "id": "5cdd419d"
    },
    {
      "cell_type": "markdown",
      "source": [
        "### To conclude:\n",
        "\n",
        "Further work involves dividing the data into train and test.\n",
        "The next step is to select a model for prediction - determining wakefulness-sleep.\n",
        "It is planned to begin this phase with the use of the random forest model."
      ],
      "metadata": {
        "id": "wx1enGJJawxh"
      },
      "id": "wx1enGJJawxh"
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fd8f99d7"
      },
      "source": [
        "### Training"
      ],
      "id": "fd8f99d7"
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8a659e1b",
        "outputId": "7f2eb424-c63e-42f6-c1b7-53ec55a9483e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-20-294a01ef19e0>:13: DeprecationWarning: `take_every` is deprecated. It has been renamed to `gather_every`.\n",
            "  train_data = train_series.filter(pl.col('series_id').is_in(series_ids)).take_every(3 * 20).collect()\n"
          ]
        }
      ],
      "source": [
        "# Collect datapoints every 5 minutes\n",
        "train_data = train_series.filter(pl.col('series_id').is_in(series_ids)).take_every(3 * 20).collect()"
      ],
      "id": "8a659e1b"
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    },
    "papermill": {
      "default_parameters": {},
      "duration": 5270.727292,
      "end_time": "2023-10-05T04:58:12.787763",
      "environment_variables": {},
      "exception": null,
      "input_path": "__notebook__.ipynb",
      "output_path": "__notebook__.ipynb",
      "parameters": {},
      "start_time": "2023-10-05T03:30:22.060471",
      "version": "2.4.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}